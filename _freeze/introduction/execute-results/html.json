{
  "hash": "722c59f991335432195c4c6a3c7827eb",
  "result": {
    "engine": "knitr",
    "markdown": "---\noutput: \n  html_document\neditor: \n  markdown: \n    wrap: 72\neditor_options: \n  chunk_output_type: console\nbibliography: [references.bib, data-cleaning-book-references.bib]\ncsl: methods-in-ecology-and-evolution.csl\ncode-annotations: hover\n---\n\n\n\n# Introduction {.unnumbered}\n\nData cleaning is a process that biologists and ecologists invariably\nhave to engage with before they can answer questions using data.\nDepending on the sources of the data, it may be necessary to standardise\nformats, correct spelling errors, and resolve taxonomic inconsistency\nand spatial errors before these data can be analysed. The \"correct\"\ndegree of data cleaning will depend on the project and the questions\nbeing asked of the data, so there is no one-size-fits-all approach.\nThere are, however, some common processes that will be broadly\napplicable to many data cleaning workflows. This book consolidates those\nprocesses into a resource for users who are interested in understanding\nhow to clean their datasets.\n\n::: figure-caption\n![Global density of 2.1 billion geo-referenced biodiversity data points\nin the Global Biodiversity Information Facility\n(GBIF)](images/hex_plot_small.png)\n:::\n\n## Who is this book for? {.unnumbered}\n\nIf you are new to working with geo-referenced biodiversity data in R, or\nare looking for a quick reference to data cleaning processes or concepts\nin R, then this book is for you! By learning how to download and apply\ncommon data cleaning steps, you will also develop a better understanding\nof biodiversity data, and common issues to be aware of.\n\n## What this book covers {.unnumbered}\n\nIn this book, we provide an overview of a typical data cleaning workflow\nfor open-access geo-referenced biodiversity data—from acquisition, to\nerror identification, to correction. These processes are broken down\ninto three main sections. The chapters within each section include\npractical guidelines, example R code, and additional resources that may\naid with each data cleaning step.\n\n:::: {layout-ncol=\"2\"}\n::: {.centre-it style=\"margin-top:auto; margin-bottom:auto;\"}\n<a href=\"1_exploring/1_intro.html\" style=\"text-decoration:none;\">\n<button class=\"circle-button\"> {{< fa magnifying-glass size=3x >}}\n</button> </a>\n:::\n\nThe first section is about **exploring data**. This section introduces\nways to inspect and summarise taxonomic, spatial, and temporal elements\nin your data to identify areas that need cleaning.\n::::\n\n------------------------------------------------------------------------\n\n:::: {layout-ncol=\"2\"}\n::: {.centre-it style=\"margin-top:auto; margin-bottom:auto;\"}\n<a href=\"2_general-cleaning/1_intro.html\" style=\"text-decoration:none;\">\n<button class=\"circle-button\"> {{< fa broom size=3x >}} </button> </a>\n:::\n\nThe second section is about **general data cleaning processes**. This\nsection provides a checklist of data science tools and functions to\nclean different aspects of your data like strings, dates, and missing\nvalues.\n::::\n\n------------------------------------------------------------------------\n\n:::: {layout-ncol=\"2\"}\n::: {.centre-it style=\"margin-top:auto; margin-bottom:auto;\"}\n<a href=\"3_ecological-cleaning/1_intro.html\" style=\"text-decoration:none;\">\n<button class=\"circle-button\"> {{< fa bugs size=3x >}} </button> </a>\n:::\n\nThe third section is about **data cleaning processes that require\nexpertise in your study species**. This section discusses ways to spot\nerrors that require ecological consideration about how best to handle\neach issue for your specific research question.\n::::\n\nThis book attempts to fill a niche between works that discuss data\ncleaning principles without using code (e.g.,\n[@chapman_principles_2005]) and articles that describe technical\nsolutions to computational problems (e.g., [the bdc\ntoolkit](https://brunobrr.github.io/bdc/#:~:text=bdc%20contains%20functions%20to%20harmonize,%2C%20spatial%2C%20and%20temporal%20data.);\n[@ribeiro_bdc_2024]).\n\nAlthough the principles we cover to clean data apply to many types of\ndata (not just biodiversity data), our perspective is strongly focused\non cleaning \"unstructured\" occurrence data with one row per observation\n(as provided by the [Global Biodiversity Information Facility\n(GBIF)](https://www.gbif.org/) and it's [partner\nnodes](https://www.gbif.org/the-gbif-network)).\n\n## What we don't cover {.unnumbered}\n\nThe areas of research and uses of biodiversity data are many and varied.\nHere we have focused on just one facet---downloading and cleaning\ngeo-referenced occurrence/biodiversity data. As such, this book will not\ncover:\n\n-   Hypothesis testing or experimental design\n-   How to clean environmental data that is not occurrence /\n    biodiversity data (e.g. trait data)\n-   How to perform analyses (e.g. species distribution modelling)\n\n## Requirements {.unnumbered}\n\n### User accounts\n\nWe will be working with point-based species occurrence data retrieved\nfrom online infrastructures such as the [Global Biodiversity Information\nFacility](https://www.gbif.org/) (GBIF) and the [Atlas of Living\nAustralia](https://www.ala.org.au/) (ALA). To retrieve data from these\nservices, you will need to create a user account, if you do not already\nhave one:\n\n-   [Register an account with Atlas of Living\n    Australia](https://auth.ala.org.au/userdetails/registration/createAccount)\n-   [Register an account with Global Biodiversity Information\n    Facility](https://www.gbif.org/user/profile)\n\n### R\n\nTo get the most out of this book, a basic knowledge of using R and\nRStudio is recommended. We use R because it is commonly used across\necological projects and has a rich ecosystem of packages for data\ncleaning and visualisation. If you are new to R or need a refresher,\nthere are many amazing and freely available resources available online.\n[Data Analysis and Visualisation in R for\nEcologists](https://datacarpentry.org/R-ecology-lesson/) and [R for Data\nScience](https://r4ds.hadley.nz/) are both excellent starting points.\n\nDownload R from [CRAN](https://cloud.r-project.org/), selecting the\nversion that matches your operating system, and install it on your\ndevice.\n\n### RStudio\n\nRStudio is an integrated development environment (IDE) for R\nprogramming. RStudio provides a range of tools to make working with R\neasier, and you can download and install RStudio for your operating\nsystem [here](https://posit.co/download/rstudio-desktop/).\n\nOther excellent IDEs like [Visual Studio\nCode](https://code.visualstudio.com/) can be good alternative options\ndepending on your preferences.\n\n### Packages\n\nWe use a range of R packages throughout the book, primarily for data\ncleaning and visualisation. These packages will be typically noted at\nthe beginning of a chapter, and occasionally a code block. To access\nbiodiversity data we will be primarily working with the\n[galah](https://galah.ala.org.au/) package. If you have collected your\nown occurrence data, you should still find this book useful.\n\nA list of the most common packages in this book can be found on the\n[Packages page](4_appendices/packages.html).\n\n## Conventions {.unnumbered}\n\n### Code blocks\n\nExamples throughout this book are accompanied by code blocks. These\nblocks show how a particular task was executed in R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is a code block with a comment\nlibrary(package-name)\nlibrary(palmerpenguins)\n\npenguins |>\n   dplyr::group_by(species)\n```\n:::\n\n\n\n::: {.callout-tip appearance=\"simple\"}\nYou can copy code by clicking the {{< fa clipboard title=\"clipboard\">}}\nbutton in the top right corner of a code block.\n:::\n\n### Code line comments\n\nSome code blocks have circled numbers near the right edge of the code\nblock. You can hover over these numbers to read additional context about\nthat specific line of code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |>\n  dplyr::group_by(species) |> # <1>\n  dplyr::summarise(mean_bill_length = mean(bill_length_mm)) # <2>\n```\n:::\n\n\n\n1.  This line of code groups `penguins` data by each distinct value in\n    the variable `species`\n2.  This line of code summarises each species' mean bill length, saving\n    the output in a new column `mean_bill_length`\n\nThroughout this book, we use “pipes” in our code (`|>`, or `%>%` from\nthe `magrittr` package). Pipes allow you to chain multiple functions\nsequentially to an object or a dataset. Pipes can be read as saying\n“*and then*”. For example, the code block above can be read as \"Get data\n`penguins`, *and then* group by `species`, *and then* summarise (setting\n`mean_bill_length` to contain the mean of `bill_length_mm`).\"\n\n## How to contribute\n\nSuggestions, contributions, questions or other feedback to improve this\nbook are welcome. We recommend opening an issue in our [GitHub\nrepository](https://github.com/AtlasOfLivingAustralia/cleaning_data/issues)\nfirst to discuss improvements or potential changes. More helpful\ninformation about licensing and contributing guidelines can be found\n[here](https://github.com/AtlasOfLivingAustralia/cleaning_data/blob/main/licensing.md).\n",
    "supporting": [
      "introduction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}